# shellcheck disable=SC2148 disable=SC1090 shell=bash

function mkcd {
  dir="$*"
  mkdir -p "$dir" && cd "$dir" || exit
}

# change /dev/null to youtube-dl-"$(date +%Y%m%d-%H%M%S)".log if you want logging

function git_sparse_clone() (
  rurl="$1" localdir="$2" && shift 2

  mkdir -p "$localdir"
  cd "$localdir"

  git init
  git remote add -f origin "$rurl"

  git sparse-checkout init

  # Loops over remaining args
  for i; do
    echo "$i" >>.git/info/sparse-checkout
  done

  git pull origin main

  git sparse-checkout list
)

# A function that checks a git repo for any incorrect casing / cashing clashes and force over-rides local changes if so
git-fix-casing() {
  local original_dir
  original_dir=$(pwd)
  cd "$1" || return 1
  sh -c 'git ls-files -ci --exclude-standard -z | xargs -0 git rm --cached'
  git status
  if [[ $(git ls-files -ci --exclude-standard) ]]; then
    echo "There are files with incorrect casing in the git repo"
    git reset --hard
    git status
  fi
  cd "$original_dir" || return 1
}

# wrapper for adding advanced git cli customisation
# alias git='git_wrapper' # disabled for now, has a few issues with things like bare repos
git_wrapper() {
  # Safely disable job control if possible
  set +m 2>/dev/null || true
  # If invoked by another function, alias or xargs, interpret it as normal
  if [[ -n ${FUNCNAME[*]} ]] || [[ -n $ALIASES ]] || [[ -n $XARGS ]]; then
    command git "$@"
    return
  fi

  # clone with depth=1 if no depth is not specified
  if [[ $1 == "clone" ]] && [[ $* != *"--depth"* ]]; then
    shift
    command git clone --depth=1 "$@"

    # Move into the cloned directory (taking into account the destination directory might be provided)
    if [[ $* == *" "* ]]; then
      local dest_dir
      dest_dir=$(echo "$*" | awk '{print $NF}')
      cd "$dest_dir"
    else
      cd "$(basename "$1" .git)"
    fi

    # Update the fetch configuration to track all upstream branches
    git config remote.origin.fetch "+refs/heads/*:refs/remotes/origin/*"

    # Fetch all branches in the background, silently
    git fetch --all --quiet #&>/dev/null &

    # Move back to the original directory
    cd -
  else
    command git "$@"
  fi
  # Safely re-enable job control if possible
  set -m 2>/dev/null || true
}

function gco() {
  if [[ -n $1 ]]; then
    if [[ $1 == "-b" ]]; then
      # shift to remove -b from args
      shift 1
    fi
    local branchname remote_branch_exist
    branchname="$1"

    # If the branch name is "main" or "master" just check it out
    if [[ "$branchname" == "main" ]] || [[ "$branchname" == "master" ]]; then
      command git switch "$branchname"
      return
    fi

    # check to see if the branch exists locally, if it doesn't offer to create it and check it out otherwise just check it out
    if command git show-ref --verify --quiet refs/heads/"$branchname"; then
      echo "Branch exists locally, switching branch..."
      command git switch "$branchname"
    else
      echo "Checking if branch exists remotely..."
      remote_branch_exist=$(command git ls-remote --heads origin "$branchname")
      if [ -n "$remote_branch_exist" ]; then
        echo "Branch exists remotely, checking out and pulling..."
        command git fetch # origin "$branchname"
        # command git checkout "$branchname" "origin/${branchname}" || echo "Error - available branches: $(git branch -v -a)"
        command git switch -c "$branchname" "origin/${branchname}" || echo "Error - available branches: $(git branch -v -a)"
        command git pull
      else
        # If the branch doesn't exist either locally or remotely
        echo "Branch doesn't exist locally or remotely, creating and switching..."
        command git switch -c "$branchname"
      fi
    fi
  else
    # shellcheck disable=SC2033
    command git branch --sort=-committerdate | fzf --header 'Checkout Recent Branch' --preview 'git diff --color=always {1}' --pointer='>' | xargs command git switch
    echo -e "${_FMT_ITL}Hint: You can check remote branches with 'gcor'${_FMT_END}"
  fi
}

# Creates a date+hour based branch
function gcd() {
  local DATESTAMP
  DATESTAMP=$(date +%Y-%m-%d-%H)
  gco -b "$DATESTAMP"
}

function gcor() {
  # List remote branches and checkout with proper tracking
  local selected remote_ref branch_name

  selected=$(command git branch -v -a | fzf --header 'Checkout Remote Branch' --preview 'git diff --color=always {1}' --pointer='>')

  [[ -z "$selected" ]] && return

  # Extract the branch reference (first field)
  remote_ref=$(echo "$selected" | awk '{print $1}')

  # Strip remotes/origin/ prefix to get the short branch name
  branch_name="${remote_ref#remotes/origin/}"

  # Check if local branch already exists
  if command git show-ref --verify --quiet "refs/heads/$branch_name"; then
    command git switch "$branch_name"
  else
    # Create local tracking branch
    command git switch -c "$branch_name" "origin/$branch_name"
  fi
}

function gbd() {
  if [[ -n $* ]]; then
    command git branch -d "$@"
  else
    # shellcheck disable=SC2033
    command git branch --sort=-committerdate | fzf --header 'Delete Git Branch' --preview 'git diff --color=always {1}' --pointer='>' | xargs command git branch -d
  fi
}


# A function that provides an untracked_files check for other functions
function __staged_changes() {
  # Display all changes including untracked files
  local STAGED_FILES
  STAGED_FILES=$(git diff --cached --name-only)
  if [[ -n "$STAGED_FILES" ]]; then
    echo "Staged files:"
    echo "$STAGED_FILES"
  else
    echo "No staged changes to add."
    # Ask the user if they want to stage all changes
    echo "Do you want to add all changes to the commit? (y/n)"
    read -r yn
    if [[ "$yn" =~ ^[Yy]$ ]]; then
      # Stage all changes
      git add .
    else
      echo "Staging cancelled by the user."
      return 1 # Return failure to indicate staging was not done
    fi
  fi
}

function checkout-hotfix() {
  local PREFIX="hotfix-${USER}"
  local DATESTAMP
  DATESTAMP=$(date +%Y-%m-%d)
  # If the hotfix branch already exists, append a number to the branch name, if the number already exists increment it
  if command git branch -a | grep -q "$PREFIX-$DATESTAMP"; then
    local COUNT=1
    while git branch -a | grep -q "$PREFIX-$DATESTAMP-$COUNT"; do
      COUNT=$((COUNT + 1))
    done
    command git checkout -b "${PREFIX}-${DATESTAMP}-${COUNT}"
  else
    command git checkout -b "${PREFIX}-${DATESTAMP}"
  fi
}

function commit-hotfix() {
  local DATESTAMP
  DATESTAMP=$(date +%Y/%m/%d)
  local GIT_ARGS=()
  local MESSAGE=""

  # Check for the '-n' flag and prepare commit options accordingly
  if [[ "$1" == "-n" ]]; then
    GIT_ARGS+=("-n") # Add '-n' to the git commit command options
    shift            # Remove '-n' from the argument list so it's not included in the commit message
  fi

  # After shifting '-n', all remaining arguments form the commit message
  MESSAGE="$*"

  # Attempt to stage changes; if the user cancels, abort the commit
  if ! __staged_changes; then
    echo "Commit aborted due to no changes being staged."
    return 1
  fi

  # Proceed with commit
  local CURRENT_BRANCH
  CURRENT_BRANCH=$(git rev-parse --abbrev-ref HEAD)
  git commit "${GIT_ARGS[@]}" -m "Hotfix-${DATESTAMP} -- ${MESSAGE}"

  # Check if the commit was successful before attempting to push
  if git rev-parse --verify "$CURRENT_BRANCH" >/dev/null 2>&1; then
    git push --set-upstream origin "$CURRENT_BRANCH"
    echo "Changes committed and pushed to $CURRENT_BRANCH."
  else
    echo "Failed to push changes. Branch $CURRENT_BRANCH does not exist."
  fi
}

function checkout-jira() {
  JIRA_BRANCH="IF-${1}-${USER}-$(date +%Y-%m-%d)"
  # If the JIRA branch already exists, append the current time to the branch name
  if command git branch -a | grep -q "remotes/origin/${JIRA_BRANCH}" || command git branch -a | grep -q "${JIRA_BRANCH}"; then
    JIRA_BRANCH="${JIRA_BRANCH}-$(date +%H-%M-%S)"
  fi
  command git checkout -b "${JIRA_BRANCH}"
}

function commit-jira() {
  local GIT_ARGS=()
  local MESSAGE=""
  local BRANCH_PREFIX CURRENT_BRANCH

  # Check for the '-n' flag and prepare commit options accordingly
  if [[ "$1" == "-n" ]]; then
    GIT_ARGS+=("-n") # Add '-n' to the git commit command options
    shift            # Remove '-n' from the argument list so it's not included in the commit message
  fi

  # After shifting '-n', all remaining arguments form the commit message
  MESSAGE="$*"

  # Call the updated function to check and stage all changes
  if ! __staged_changes; then
    echo "Commit aborted due to no changes being staged."
    return 1
  fi

  # add the branch prefix to the message (e.g. IF-1234 -- message)
  CURRENT_BRANCH=$(git rev-parse --abbrev-ref HEAD)
  BRANCH_PREFIX=$(echo "$CURRENT_BRANCH" | cut -d'-' -f1 -f2)
  MESSAGE="${BRANCH_PREFIX} -- ${MESSAGE}"

  # Proceed with commit
  if ! git diff --cached --quiet; then
    echo "No changes to commit."
    # Check if the branch exists on the remote
    if ! git ls-remote --heads origin "$CURRENT_BRANCH" | grep -q "$CURRENT_BRANCH"; then
      # Offer to push and track the branch if it doesn't exist on the remote
      echo "Current branch '$CURRENT_BRANCH' does not exist on the remote. Would you like to push it? (y/n)"
      read -r yn
      if [[ "$yn" =~ ^[Yy]$ ]]; then
        git push --set-upstream origin "$CURRENT_BRANCH"
        echo "Branch pushed and tracked on remote."
      else
        echo "Push cancelled by the user."
      fi
    fi
  else
    # Execute the commit with any options and the message
    git commit "${GIT_ARGS[@]}" -m "$MESSAGE"
    git push --set-upstream origin "$CURRENT_BRANCH"
    echo "Changes committed and pushed to '$CURRENT_BRANCH'."
  fi
}

# Outputs the name of the current branch
# Usage example: git pull origin "$(git_current_branch)"
# Using '--quiet' with 'symbolic-ref' will not cause a fatal error (128) if
# it's not a symbolic ref, but in a Git repo.
function git_current_branch() {
  local ref
  ref=$(command git symbolic-ref --quiet HEAD 2>/dev/null)
  local ret=$?
  if [[ $ret != 0 ]]; then
    [[ $ret == 128 ]] && return # no git repo.
    ref=$(command git rev-parse --short HEAD 2>/dev/null) || return
  fi
  echo "${ref#refs/heads/}"
}

function pr-checkout() {
  local jq_template pr_number

  jq_template='"''#\(.number) - \(.title)''\t''Author: \(.user.login)\n''Created: \(.created_at)\n''Updated: \(.updated_at)\n\n''\(.body)''"'

  pr_number=$(
    gh api 'repos/:owner/:repo/pulls' |
      jq ".[] | $jq_template" |
      sed -e 's/"\(.*\)"/\1/' -e 's/\\t/\t/' |
      fzf \
        --with-nth=1 \
        --delimiter='\t' \
        --preview='echo -e {2}' \
        --preview-window=top:wrap |
      sed 's/^#\([0-9]\+\).*/\1/'
  )

  if [ -n "$pr_number" ]; then
    gh pr checkout "$pr_number"
  fi
}

function git_add_global_prepush_hook() {
  local repo_path=$1
  local branch_name=$2
  local hooks_path="$repo_path/.git/hooks"

  # Check if the repo_path is a Git repository
  if [ ! -d "$repo_path/.git" ]; then
    echo "$repo_path is not a Git repository"
    return 1
  fi

  # Create the pre-push hook if it doesn't exist
  if [ ! -f "$hooks_path/pre-push" ]; then
    touch "$hooks_path/pre-push"
    chmod +x "$hooks_path/pre-push"
  fi

  # Add the code to the pre-push hook
  cat <<EOF >>"$hooks_path/pre-push"
#!/usr/bin/env bash

# This script can be run as a pre-push hook locally on repositories to add messages / ensure we're not pushing to the wrong branch etc...

branch_name=$(git symbolic-ref --short HEAD)
if [ "$branch_name" == "main" ] || [ "$branch_name" == "master" ]; then
  echo "WARNING: You are pushing to the $branch_name branch!"
  read -r -p "Are you sure you want to push to $branch_name? [y/N] " response
  if [[ "$response" =~ ^([yY][eE][sS]|[yY])$ ]]; then
    echo "$response - Pushing to $branch_name"
  else
    echo "Aborting push"
    exit 1
  fi
fi
EOF

  echo "Global pre-push hook added to $repo_path"
}

# Gets the number of commits ahead from remote
function git_commits_ahead() {
  if command git rev-parse --git-dir &>/dev/null; then
    local commits
    commits="$(git rev-list --count @{upstream}..HEAD)"
    if [[ "$commits" != 0 ]]; then
      echo "$ZSH_THEME_GIT_COMMITS_AHEAD_PREFIX$commits$ZSH_THEME_GIT_COMMITS_AHEAD_SUFFIX"
    fi
  fi
}

# Gets the number of commits behind remote
function git_commits_behind() {
  if command git rev-parse --git-dir &>/dev/null; then
    local commits
    commits="$(git rev-list --count HEAD..@{upstream})"
    if [[ "$commits" != 0 ]]; then
      echo "$ZSH_THEME_GIT_COMMITS_BEHIND_PREFIX$commits$ZSH_THEME_GIT_COMMITS_BEHIND_SUFFIX"
    fi
  fi
}

# Outputs if current branch is ahead of remote
function git_prompt_ahead() {
  if [[ -n "$(command git rev-list origin/"$(git_current_branch)"..HEAD 2>/dev/null)" ]]; then
    echo "$ZSH_THEME_GIT_PROMPT_AHEAD"
  fi
}

# Outputs if current branch is behind remote
function git_prompt_behind() {
  if [[ -n "$(command git rev-list HEAD..origin/"$(git_current_branch)" 2>/dev/null)" ]]; then
    echo "$ZSH_THEME_GIT_PROMPT_BEHIND"
  fi
}

# Outputs if current branch exists on remote or not
function git_prompt_remote() {
  if [[ -n "$(command git show-ref origin/"$(git_current_branch)" 2>/dev/null)" ]]; then
    echo "$ZSH_THEME_GIT_PROMPT_REMOTE_EXISTS"
  else
    echo "$ZSH_THEME_GIT_PROMPT_REMOTE_MISSING"
  fi
}

# Formats prompt string for current git commit short SHA
function git_prompt_short_sha() {
  local SHA
  SHA=$(command git rev-parse --short HEAD 2>/dev/null) && echo "$ZSH_THEME_GIT_PROMPT_SHA_BEFORE$SHA$ZSH_THEME_GIT_PROMPT_SHA_AFTER"
}

# Formats prompt string for current git commit long SHA
function git_prompt_long_sha() {
  local SHA
  SHA=$(command git rev-parse HEAD 2>/dev/null) && echo "$ZSH_THEME_GIT_PROMPT_SHA_BEFORE$SHA$ZSH_THEME_GIT_PROMPT_SHA_AFTER"
}

# # Get the status of the working tree
# function git_prompt_status() {
#   local INDEX STATUS
#   INDEX=$(command git status --porcelain -b 2>/dev/null)
#   STATUS=""
#   if eval "$(echo "$INDEX" | command grep -E '^\?\? ' &>/dev/null)"; then
#     STATUS="$ZSH_THEME_GIT_PROMPT_UNTRACKED$STATUS"
#   fi
#   if eval "$(echo "$INDEX" | grep '^A  ' &>/dev/null)"; then
#     STATUS="$ZSH_THEME_GIT_PROMPT_ADDED$STATUS"
#   elif eval "$(echo "$INDEX" | grep '^M  ' &>/dev/null)"; then
#     STATUS="$ZSH_THEME_GIT_PROMPT_ADDED$STATUS"
#   fi
#   if eval "$(echo "$INDEX" | grep '^ M ' &>/dev/null)"; then
#     STATUS="$ZSH_THEME_GIT_PROMPT_MODIFIED$STATUS"
#   elif eval "$(echo "$INDEX" | grep '^AM ' &>/dev/null)"; then
#     STATUS="$ZSH_THEME_GIT_PROMPT_MODIFIED$STATUS"
#   elif eval "$(echo "$INDEX" | grep '^ T ' &>/dev/null)"; then
#     STATUS="$ZSH_THEME_GIT_PROMPT_MODIFIED$STATUS"
#   fi
#   if eval "$(echo "$INDEX" | grep '^R  ' &>/dev/null)"; then
#     STATUS="$ZSH_THEME_GIT_PROMPT_RENAMED$STATUS"
#   fi
#   if eval "$(echo "$INDEX" | grep '^ D ' &>/dev/null)"; then
#     STATUS="$ZSH_THEME_GIT_PROMPT_DELETED$STATUS"
#   elif eval "$(echo "$INDEX" | grep '^D  ' &>/dev/null)"; then
#     STATUS="$ZSH_THEME_GIT_PROMPT_DELETED$STATUS"
#   elif eval "$(echo "$INDEX" | grep '^AD ' &>/dev/null)"; then
#     STATUS="$ZSH_THEME_GIT_PROMPT_DELETED$STATUS"
#   fi
#   if eval "$(command git rev-parse --verify refs/stash >/dev/null 2>&1)"; then
#     STATUS="$ZSH_THEME_GIT_PROMPT_STASHED$STATUS"
#   fi
#   if eval "$(echo "$INDEX" | grep '^UU ' &>/dev/null)"; then
#     STATUS="$ZSH_THEME_GIT_PROMPT_UNMERGED$STATUS"
#   fi
#   if eval "$(echo "$INDEX" | grep '^## [^ ]\+ .*ahead' &>/dev/null)"; then
#     STATUS="$ZSH_THEME_GIT_PROMPT_AHEAD$STATUS"
#   fi
#   if eval "$(echo "$INDEX" | grep '^## [^ ]\+ .*behind' &>/dev/null)"; then
#     STATUS="$ZSH_THEME_GIT_PROMPT_BEHIND$STATUS"
#   fi
#   if eval "$(echo "$INDEX" | grep '^## [^ ]\+ .*diverged' &>/dev/null)"; then
#     STATUS="$ZSH_THEME_GIT_PROMPT_DIVERGED$STATUS"
#   fi
#   echo "$STATUS"
# }

# #  TODO: replace this with something more standard, this was a temporary workaround for poor performance of the stock oh-my-zsh git plugin
# # Compares the provided version of git to the version installed and on path
# # Outputs -1, 0, or 1 if the installed version is less than, equal to, or
# # greater than the input version, respectively.
# function git_compare_version() {
#   local INPUT_GIT_VERSION INSTALLED_GIT_VERSION
#   # shellcheck disable=SC2206,SC2207,SC2296
#   INPUT_GIT_VERSION=(${(s/./)1})
#   # shellcheck disable=SC2206,SC2207,SC2296
#   INSTALLED_GIT_VERSION=($(command git --version 2>/dev/null))
#   # shellcheck disable=SC2206,SC2207,SC2296
#   INSTALLED_GIT_VERSION=(${(s/./)INSTALLED_GIT_VERSION[3]})

#   for i in {1..3}; do
#     if [[ ${INSTALLED_GIT_VERSION[$i]} -gt ${INPUT_GIT_VERSION[$i]} ]]; then
#       echo 1
#       return 0
#     fi
#     if [[ ${INSTALLED_GIT_VERSION[$i]} -lt ${INPUT_GIT_VERSION[$i]} ]]; then
#       echo -1
#       return 0
#     fi
#   done
#   echo 0
# }

# Outputs the name of the current user
# Usage example: $(git_current_user_name)
function git_current_user_name() {
  command git config user.name 2>/dev/null
}

# Outputs the email of the current user
# Usage example: $(git_current_user_email)
function git_current_user_email() {
  command git config user.email 2>/dev/null
}

# Clean up the namespace slightly by removing the checker function
# unfunction git_compare_version

#source /usr/local/etc/profile.d/autojump.sh

pdfcompress() {
  gs -q -dNOPAUSE -dBATCH -dSAFER -sDEVICE=pdfwrite -dCompatibilityLevel=1.3 -dPDFSETTINGS=/screen -dEmbedAllFonts=true -dSubsetFonts=true -dColorImageDownsampleType=/Bicubic -dColorImageResolution=144 -dGrayImageDownsampleType=/Bicubic -dGrayImageResolution=144 -dMonoImageDownsampleType=/Bicubic -dMonoImageResolution=144 -sOutputFile="$1".compressed.pdf "$1"
}

# Usage: mv oldfilename
# If you call mv without the second parameter it will prompt you to edit the filename on command line.
# Original mv is called when it's called with more than one argument.
# It's useful when you want to change just a few letters in a long name.

function mv() {
  if [ "$#" -ne 1 ]; then
    command mv "$@"
    return
  fi
  if [ ! -f "$1" ]; then
    command file "$@"
    return
  fi

  read -ei "$1" newfilename
  mv -v "$1" "$newfilename"
}

_force_rehash() {
  ((CURRENT == 1)) && rehash
  return 1 # Because we didn't really complete anything
}

# This was causing tab complete errors such as zle-line-init:1: command not found
# edit-command-output() {
#   BUFFER=$(eval "$BUFFER")
#   CURSOR=0
# }
# zle -N edit-command-output

__mkdir() { if [[ ! -d $1 ]]; then mkdir -p "$1"; fi; }

tch() {
  for x in "$@"; do
    __mkdir "${x:h}"
  done
  touch "$@"
}

# Interactive git diff
function git-diff() {
  git log --graph --color=always \
    --format="%C(auto)%h%d %s %C(black)%C(bold)%cr" "$@" |
    fzf --ansi --preview "echo {} \
    | grep -o '[a-f0-9]\{7\}' \
    | head -1 \
    | xargs -I % sh -c 'git show --color=always %'" \
      --bind "enter:execute:
            (grep -o '[a-f0-9]\{7\}' \
                | head -1 \
                | xargs -I % sh -c 'git show --color=always % \
                | less -R') << 'FZF-EOF'
            {}
FZF-EOF"
}

# Github
# Deletes workflow logs from a given repo older than 1 month
# e.g. USER=myuser REPO=myrepo ghac
function ghac() {
  DATE=$(date -v "-1m" +"%Y-%m-%d") gh api "repos/${USER}/${REPO}/actions/runs" --paginate -q '.workflow_runs[] | select (.run_started_at  <= "env.DATE") | (.id)' |
    xargs -n1 -I % gh api "repos/${USER}/${REPO}/actions/runs"/% -X DELETE
}

function github_actions_watcher() {
  # https://github.com/nedbat/watchgha
  TOKEN_BACKUP=$GITHUB_TOKEN
  unset GITHUB_TOKEN
  watch_gha_runs "$@" \
    "$(git remote get-url origin)" \
    "$(git rev-parse --abbrev-ref HEAD)"
  GITHUB_TOKEN=$TOKEN_BACKUP
}

# Git checkout new branch, git add, git commit, git push in all subdirectories matching a pattern
function git_add_commit_push() {
  if [[ -z $1 ]] || [[ -z "$2" ]] || [[ -z "$3" ]]; then
    echo 'You must pass three paramters, branchname, commit message, dir match - e.g. "my-branch" "commit message" ABC*'
  fi
  BRANCHNAME="$1"
  COMMITNAME="$2"
  MATCHDIRS="$3"
  for dir in $MATCHDIRS; do
    (
      cd "$dir" &&
        git checkout -b "$BRANCHNAME" &&
        git add . &&
        git commit -n -m "$COMMITNAME" &&
        git push
    )
  done
}

# Interactive cd using fzf
function fcd() {
  local dir

  while true; do
    # exit with ^D
    dir="$(ls -a1p | grep '/$' | grep -v '^./$' | fzf --height 40% --reverse --no-multi --preview 'pwd' --preview-window=up,1,border-none --no-info)"
    if [[ -z "${dir}" ]]; then
      break
    else
      cd "${dir}" || exit
    fi
  done
}

# list env variables with fzf
list_env() {
  var=$(printenv | cut -d= -f1 | fzf) &&
    echo "$var=$(printenv "$var")" &&
    unset var
}

# Encryption (using age)

# File with generated password
encrypt_file_pw() {
  # Suggest installing age if not installed
  if ! command -v age &>/dev/null; then
    echo "age could not be found. Install it with 'brew install age'"
    return
  else
    age -p "$1" -o "${1}.age"
  fi
}

conda_setup() {
  # CONDA - is managed via a function when needed
  # >>> conda initialize >>>
  # !! Contents within this block are managed by 'conda init' !!
  __conda_setup="$('/Users/samm/miniconda3/bin/conda' 'shell.zsh' 'hook' 2>/dev/null)"
  if [ $? -eq 0 ]; then
    eval "$__conda_setup"
  else
    if [ -f "/Users/samm/miniconda3/etc/profile.d/conda.sh" ]; then
      . "/Users/samm/miniconda3/etc/profile.d/conda.sh"
    else
      export PATH="/Users/samm/miniconda3/bin:$PATH"
    fi
  fi
  unset __conda_setup
  # <<< conda initialize <<<
}

function update_asdf() {
  asdf update
  asdf plugin-update --all
}

# Prompts for a name and a password and stores it in keychain
keychain_password_prompt() {
  echo "Enter a name for the password:"
  read -r name
  echo "Enter the password:"
  stty -echo # disable echoing the password
  read -r password
  security add-generic-password -s "$name" -a "$(whoami)" -w "$password"
  stty echo # re-enable echoing
}

# Reads a password from keychain and outputs it
# usage: keychain_password <service name to match on> <account>
keychain_password() {
  stty -echo # disable echoing the password
  security find-generic-password -s "$1" -a "$(whoami)" -w
  stty echo # re-enable echoing
}

### AWS Auth ###
# aws-profile uses s2a-keychain to login to AWS using saml2aws and then exports the AWS_PROFILE variable
# Requires saml2aws, fzf, and keychain_password
alias aad=aws-profile
alias awslogin=aws-profile
alias aws-azure-login=aws-profile

# shellcheck disable=SC2068 disable=SC2046 disable=SC2145
function s2a() {
  eval $($(command saml2aws) script --shell=bash --profile=$@)
}

# Logs into AWS using saml2aws and a password stored in keychain
function s2a-keychain() {
  local IDPPW INPUT_PROFILE KEYCHAIN_ITEM
  KEYCHAIN_ITEM=${KEYCHAIN_ITEM:-"saml2awspw"}
  INPUT_PROFILE=${1:-"default"}
  CHECK_SCREENRECORDER=${CHECK_SCREENRECORDER:-"false"}

  IDPPW=$(keychain_password "$KEYCHAIN_ITEM") # requires mfa and keychain authentication

  aws configure list --profile "${INPUT_PROFILE}"

  # Login to AWS
  # /Users/samm/git/saml2aws-fork/dist/saml2aws_darwin_arm64/saml2aws
  saml2aws login -a "$INPUT_PROFILE" \
    --skip-prompt \
    --password="$IDPPW" \
    --profile="$INPUT_PROFILE"
  # --skip-verify
  export AWS_PROFILE="$INPUT_PROFILE"
  export AWSCLIPARAMS="--profile=${INPUT_PROFILE}"
  export AWS_DEFAULT_REGION=ap-southeast-2
  unset IDPPW
}

# Interactively export AWS_PROFILE
function aws-profile() {
  # if provided an argument, use that as the profile
  if [[ -n $1 ]]; then
    export AWS_PROFILE=$1
    export AWSCLIPARAMS="--profile=$1"
  else
    # otherwise, use fzf to select a profile
    AWS_PROFILE=$(grep profile "${HOME}"/.aws/config |
      awk '{print $2}' | sed 's,],,g' |
      fzf --layout reverse --height=30% --border)
    export AWS_PROFILE
    export AWSCLIPARAMS="--profile=${AWS_PROFILE}"
  fi
  s2a-keychain "$AWS_PROFILE"

  echo "[You are now using the ${AWS_PROFILE} profile]"
}

### END AWS Auth ###

# A function that checks ssh-add and adds my keys if they're not already added
function ssh-add-keys() {
  if ! ssh-add -l | grep -qe 'ED25519\|RSA'; then
    ssh-add --apple-use-keychain ~/.ssh/id_*.key
  fi
}

function tmux_create() {
  SESSION="$1"
  echo "Creating tmux session ${SESSION}"
  tmux new-session -d -s "$SESSION"
  tmux switch-client -t "$SESSION"
}

function tmux_attach() {
  # If not provided an argument, use fzf to select a session
  if [[ -n $1 ]]; then
    SESSION="$1"

    # check if there are any sessions
    if [[ -z $(tmux ls) ]]; then
      echo "No tmux sessions found"
      return 1
    fi
  else
    SESSION=$(tmux ls | grep -Eo '^[0-9]+.*' | fzf --layout reverse --height=40% --border | awk '{print $1}')
  fi
  echo "Attaching to tmux session ${SESSION}"
  tmux switch-client -t "$SESSION"
}

clean_string() {
  # Escape special characters in a string such as $, ", ', `, \, and newline.
  # Usage: escape_string "string to escape"
  local string="${1}"
  local escaped_string
  escaped_string=$(printf '%q' "${string}")
  echo "${escaped_string}"
}

docker_login_ghcr() {
  # Dependencies: gh
  set -e

  if [ ! -f ~/.docker/config.json ]; then
    echo '{"credsStore": "desktop","credHelpers": {"docker.pkg.github.com": "gh","ghcr.io": "gh"}}' >~/.docker/config.json
  fi

  cmd="${1}"
  if [ "erase" = "${cmd}" ]; then
    cat - >/dev/null
    exit 0
  fi
  if [ "store" = "${cmd}" ]; then
    cat - >/dev/null
    exit 0
  fi
  if [ "get" != "${cmd}" ]; then
    exit 1
  fi

  host="$(cat -)"
  host="${host#https://}"
  host="${host%/}"
  if [ "${host}" != "ghcr.io" ] && [ "${host}" != "docker.pkg.github.com" ]; then
    exit 1
  fi

  token="$(gh config get -h github.com oauth_token)"
  if [ -z "${token}" ]; then
    exit 1
  fi

  printf '{"Username":"%s", "Secret":"%s"}\n' "$(gh config get -h github.com user)" "${token}"
}

docker_inspect_all() {
  # Get the IDs of all running containers
  local container_ids=("$(docker ps -q)")

  # Iterate over each container ID
  for container_id in "${container_ids[@]}"; do
    # Run docker inspect command and store the output in a variable
    local inspect_output=$(docker inspect --format='{{json .}}' "$container_id")

    # Extract container name and remove leading '/'
    local container_name=$(jq -r '.Name[1:]' <<<"$inspect_output")

    # Extract container status, creation timestamp, and IP addresses
    local container_status=$(jq -r '.State.Status' <<<"$inspect_output")
    local created_timestamp=$(jq -r '.Created' <<<"$inspect_output")
    local ip_address=$(jq -r '.NetworkSettings.Networks[].IPAddress' <<<"$inspect_output")
    local ipv6_address=$(jq -r '.NetworkSettings.Networks[].GlobalIPv6Address' <<<"$inspect_output")

    # Extract forwarded ports
    local ports=$(jq -r '.NetworkSettings.Ports | to_entries[] | .key + " -> " + .value[0].HostPort' <<<"$inspect_output")

    # Display the extracted information
    echo "Container ID: $container_id"
    echo "Container Name: $container_name"
    echo "Container Status: $container_status"
    echo "Created Timestamp: $created_timestamp"
    echo "IP Address: $ip_address"
    echo "IPv6 Address: $ipv6_address"
    echo "Forwarded Ports: $ports"
    echo "-----------------------"
  done
}

ps-docker() {
  # ps -aux but with the container name and nice formatting
  echo -e "Processing docker containers, this may take a moment...\n"
  {
    echo -e "CONTAINER NAME\tUSER\tPID\t%CPU\t%MEM\tRUN TIME\tCOMMAND"
    ps -aux | awk '{print $2}' | while read pid; do
      container_id=$(grep -Eo "docker-([a-f0-9]{64})\.scope" /proc/"$pid"/cgroup 2>/dev/null | head -n1 | grep -Eo "([a-f0-9]{64})")
      if [ ! -z "$container_id" ]; then
        container_name=$(docker ps --no-trunc | grep "$container_id" | awk '{print $NF}')
        if [ ! -z "$container_name" ]; then
          ps -p "$pid" -o user,pid,%cpu,%mem,etime,cmd --no-headers | awk -v cn="$container_name" '{printf "%-20s\t%-8s\t%-8s\t%-5s\t%-5s\t%-10s\t%-40s\n", cn, $1, $2, $3, $4, $5, substr($0, index($0,$6))}'
        fi
      fi
    done
  } | awk 'BEGIN {OFS="\t"; prev="none"} NR==1 {print} NR>1 {split($0,a,"\t"); if (a[1]!=prev && NR>2) print "--------------------\t\t\t\t\t\t\t"; print; prev=a[1]}'
}

# 3D Printing
function cura-backup() {
  # Zip up the latest cura config from the newest number cura config directory (~/Library/Application\ Support/cura/(number.number) (e.g. 4.8)
  # and copy it to the cloud backup folder
  local cura_base_dir="${HOME}/Library/Application Support/cura"
  local destination="${HOME}/Library/Mobile Documents/com~apple~CloudDocs/Backups/3dprinting/cura"
  local latest_version_dir="$(ls -d "${cura_base_dir}"/*/ | tail -n1)"

  # zip it up with the date
  local date="$(date +%Y-%m-%d)"
  local zip_file="${destination}/cura-${date}.zip"
  zip -r "${zip_file}" "${latest_version_dir}"
  echo "Created ${zip_file}"
}

function ripSearch() {
  # 1. Search for text in files using Ripgrep
  # 2. Interactively narrow down the list using fzf
  # 3. Open the file in vscode

  while getopts n OPTION; do
    case "${OPTION}" in
    n) NEW_WINDOW="--new-window" ;;
    *) echo "ERROR: we only support -n" && exit 1 ;;
    esac
  done
  shift $((OPTIND - 1))

  : "${NEW_WINDOW:=""}"

  # Allow the function to be cancelled with Ctrl-C, but don't exit the shell
  trap 'return 1' INT

  ARGLIST=""
  while IFS=: read -rA SELECTED; do
    if [ "${#SELECTED[@]}" -gt 0 ]; then
      ARGLIST+="--goto ${SELECTED[0]}:${SELECTED[1]} "
    fi
  done < <(
    rg --color=always --line-number --no-heading --smart-case "${*:-}" |
      fzf --ansi \
        --color "hl:-1:underline,hl+:-1:underline:reverse" \
        --delimiter : \
        --multi \
        --preview 'bat --color=always {1} --highlight-line {2} --style=header,grid {}' \
        --preview-window 'right,60%,border-bottom,+{2}+3/3,~3'
  )
  if [ -n "${ARGLIST}" ]; then
    code "${NEW_WINDOW}" "${ARGLIST}"
  fi
}

### CAPTURE AND RETURN OUTPUT OF A COMMAND ###
# Usage:
# $ find . -name 'filename' | cap
# /path/to/filename
# $ ret
# /path/to/filename

# capture the output of a command so it can be retrieved with ret
cap() { tee /tmp/capture.out; }

# return the output of the most recent command that was captured by cap
ret() { cat /tmp/capture.out; }
### END CAPTURE AND RETURN OUTPUT OF A COMMAND ###

# Backup VSCode extensions settings
function backup-vscode() {
  local date
  date="$(date +%Y-%m-%d)"
  local destination="${HOME}/Library/Mobile Documents/com~apple~CloudDocs/Backups/vscode/${date}"
  local extensions_file="${destination}/extensions.txt"
  local settings_file="${destination}/settings.json"
  local keybindings_file="${destination}/keybindings.json"

  mkdir -p "${destination}"

  # List extensions
  code --list-extensions >"${extensions_file}"
  echo "Created ${extensions_file}"

  # Backup settings
  cp "${HOME}/Library/Application Support/Code/User/settings.json" "${settings_file}"
  echo "Created:"
  echo "$settings_file"

  # Backup keybindings
  cp "${HOME}/Library/Application Support/Code/User/keybindings.json" "${keybindings_file}"
  echo "$keybindings_file"
}

### Github Functions ###
function gh() {
  # unset GITHUB_TOKEN for gh cli
  GITHUB_TOKEN="" command gh "$@"
}

function gh_pr_list_open() {
  local search_param=""
  local other_params=()

  while [[ $# -gt 0 ]]; do
    case "$1" in
    --match)
      search_param="$2"
      shift 2
      ;;
    *)
      other_params+=("$1")
      shift
      ;;
    esac
  done

  if [[ -n "$search_param" ]]; then
    other_params+=("--search=\"$search_param\"")
  fi

  gh pr list --state open "${other_params[@]}"
}

function gh_pr_list_open_dir_repos() {
  local search_param=""
  local other_params=()

  while [[ $# -gt 0 ]]; do
    case "$1" in
    --match)
      search_param="$2"
      shift 2
      ;;
    *)
      other_params+=("$1")
      shift
      ;;
    esac
  done

  for repo in */; do
    if [[ -d "$repo" ]]; then
      # Get the repo name from the git config
      repo_name=$(git -C "$repo" config --get remote.origin.url | sed -E 's/.*github.com[:/].*\/(.*)\.git/\1/')
      # Get the repo owner from the git config
      repo_owner=$(git -C "$repo" config --get remote.origin.url | sed -E 's/.*github.com[:/](.*)\/.*/\1/')

      echo "Repository: $repo_owner/$repo_name"

      gh_pr_list_open --repo "$repo_owner/$repo_name" --match "$search_param" "${other_params[@]}"

      echo ""
    fi
  done
}

function gh_pr_merge_matching() {
  local search_param="$1"
  local other_params=()

  while [[ $# -gt 0 ]]; do
    case "$1" in
    --match)
      search_param="$2"
      shift 2
      ;;
    *)
      other_params+=("$1")
      shift
      ;;
    esac
  done

  local pr_numbers=()
  gh_pr_list_open --match "$search_param" "${other_params[@]}" | while IFS= read -r pr_info; do
    pr_number=$(echo "$pr_info" | jq -r '.number')
    pr_numbers+=("$pr_number")
    echo "PR #$pr_number: $(echo "$pr_info" | jq -r '.title')"
  done

  if [[ ${#pr_numbers[@]} -eq 0 ]]; then
    echo "No matching PRs found."
    return 1
  fi

  read -p "Merge and resolve these PRs? (y/n): " choice
  if [[ $choice == [yY] ]]; then
    for pr_number in "${pr_numbers[@]}"; do
      gh pr merge "$pr_number" --auto "${other_params[@]}"
    done
  fi
}

### END Github Functions ###

### Get output from last command ###
# CTRL+Q,CTRL+L
zmodload -i zsh/parameter

insert-last-command-output() {
  # shellcheck disable=SC2154
  LBUFFER+="$(eval "$history"[$((HISTCMD - 1))])"
}
zle -N insert-last-command-output

bindkey "^Q^L" insert-last-command-output
### End get output from last command ###

# if ifup or ifdown is run - remind the user of the correct
ifup() {
  echo "Did you mean 'ip link set $1 up'?"
}

ifdown() {
  echo "Did you mean 'ip link set $1 down'?"
}

# A small function that updates chromium (don't worry - my main browser is Firefox) and removes the extended attributes that cause it to be quarantined by macOS
__update_chromium() {
  # check if there is an update available from homebrew
  local chromium_update
  chromium_update=$(brew outdated --cask --greedy | grep -i chromium)

  if [[ -n $chromium_update ]]; then
    brew upgrade --cask --greedy --no-quarantine chromium
    xattr -d com.apple.quarantine /Applications/Chromium.app
    echo "Updated Chromium to $chromium_update, and removed quarantine attributes."
  fi
}

# a function that checks for macOS OS updates and downloads them (without installing) then pops up a notification in the background
function __update_macos() {
  # check for updates
  softwareupdate -l
  if [[ $? -eq 0 ]]; then
    # notify the user there are updates to download and that they may have to enter their password in the terminal
    osascript -e 'display notification "macOS updates are available. You may need to enter your password in the terminal to download them." with title "macOS Update" action button "Show iTerm"'
    # download updates
    softwareupdate -d -a --no-scan --agree-to-license --background
  fi
}

function ba() {
  # trap ctrl-c
  trap '' SIGINT

  # create a log file, if it already exists move it to .1 and create a new one
  local log_file="${HOME}/.ba.log"
  local error_log="${HOME}/.ba.errors.log"

  if [[ -f "${log_file}" ]]; then
    mv -f "${log_file}" "${log_file}.1"
  fi
  touch "$log_file"

  # link all ollama models to lm-studio
  gollama -L -H >>"${log_file}" 2>&1 &

  # update vscode packages
  code --update-extensions >>"${log_file}" 2>&1 &
  gh extension upgrade --all >>"${log_file}" 2>&1 &

  # Update Claude Code
  claude update >>"${log_file}" 2>&1 &

  # Update global npm packages (if they match the allowlist)
  npm-global-update

  uv tool install claude-monitor -U >>"${log_file}" 2>&1 &
  uv tool install claude-code-tools -U >>"${log_file}" 2>&1 &
  uv tool install mistral-vibe -U >>"${log_file}" 2>&1 &
  pip install -U yt-dlp >>"${log_file}" 2>&1 &

  # update homebrew and all apps
  brew update >>"${error_log}" 2>&1

  echo "Upgrading shell and packages in the background, tail -f ${log_file} for details."

  touch "${log_file}" "${error_log}"
  echo "Starting update at $(date +%Y-%m-%d) ..." >>"${log_file}"

  __upgrade_shell >>"${log_file}" 2>&1 &
  __upgrade_packages >>"${log_file}" 2>&1 &

  echo "Upgrading apps in the foreground..."
  __upgrade_apps # >>"${log_file}"

  echo "Checking and downloading macOS updates in the background..."
  __update_macos >>"${log_file}" 2>&1 &

  /Users/samm/bin/build_ollama.sh >>"${log_file}" 2>&1 &

  echo "Upgrading rust in the background..."
  rustup update >>"${log_file}" 2>&1 &

  echo "Updating Github Copilot CLI in the background..."
  gh extension upgrade gh-copilot >>"${log_file}" 2>&1 &

  # list all background jobs
  jobs

  # every 5 seconds, check if any background jobs are paused, if so, foreground them
  while true; do
    sleep 5
    if [[ -n $(jobs -p -s) ]]; then
      sleep 1
      echo -e ""
      fg
    else
      break
    fi
  done

  # wait for all background jobs to finish
  wait
  # fix chromedriver quarantine
  xattr -c /opt/homebrew/Caskroom/chromedriver/*/chromedriver-mac-arm64/chromedriver
  fg # bring the last background job to the foreground

  compdump # recompile zsh completion files

  echo "Updates complete, see ${log_file} for details."

  # unset trap
  trap - SIGINT
}

function __upgrade_apps() {
  trap 'fg' SIGINT

  brew update
  NONINTERACTIVE=1 __update_chromium
  NONINTERACTIVE=1 brew upgrade --greedy --greedy-latest
  NONINTERACTIVE=1 brew upgrade --cask --greedy
  NONINTERACTIVE=1 mas upgrade
  brew cleanup
  brew autoremove
  gup update

  # unset trap
  trap - SIGINT

  # check for any suspended jobs and foreground them
  if [[ -n $(jobs -p -s) ]]; then
    fg
  fi
}

function __upgrade_packages() {
  trap 'fg' SIGINT

  pip3 install -U pip
  npm i -g npm-check-updates
  \ncu --global
  echo | vim +PluginInstall +qall &>/dev/null

  # unset trap
  trap - SIGINT
}

function __upgrade_shell() {
  zgen selfupdate
  zgen update
  omz update
}

function __upgrade_docker_compose() {
  VERSION=$(curl --silent https://api.github.com/repos/docker/compose/releases/latest | jq .name -r)
  DESTINATION=/usr/local/bin/docker-compose
  COMPOSE_LOCATION=$(which docker-compose 2>/dev/null)

  # Check if we've got docker-compose already installed and if we're using the homebrew version
  if [[ $COMPOSE_LOCATION == "/opt/homebrew/bin/docker-compose" ]]; then
    echo "You're using the homebrew version of docker-compose, skipping update."
    return
  fi

  if [[ -f $DESTINATION ]] && [[ $(docker-compose version --short) == "$VERSION" ]]; then
    echo "docker-compose is already up to date."
    return
  else
    curl -L "https://github.com/docker/compose/releases/download/${VERSION}/docker-compose-$(uname -s)-$(uname -m)" -o "$DESTINATION"
    chmod 755 "$DESTINATION"
    ln -fs "$(which docker-compose)" /usr/libexec/docker/cli-plugins/docker-compose
    echo "Updated docker-compose to ${VERSION}"
  fi
}

# Now in 1-zgen.rc
# bg_silent() {
#   # background a task quietly and disown
#   { "$@" 2>&3 & } 3>&2 2>/dev/null
#   disown &>/dev/null
# }

### OLD
# # AWS Azure AD login
# function aws-azure-login() {
#   command aws-azure-login --no-prompt --profile "$@"
#   export AWS_PROFILE=$*
#   export AWSCLIPARAMS="--profile=$*"
# }

# # saml2aws
# aad() {
#   local IDPPW INPUT_PROFILE

#   # Check for input
#   if [ -z "${1}" ]; then
#     echo "ERROR: account name required, e.g. $(basename "$0") data-dev"
#     return 1
#   else
#     # Cleanup the input
#     INPUT_PROFILE=$(echo "$1" | sed -e 's/dosa/kis/g;s/cust/klue/g')
#   fi

#   # Fetch the password from keychain
#   IDPPW=$(keychain_password awsazurepw) # requires mfa and keychain authentication

#   aws configure list --profile "${1}"
#   # Login to AWS
#   saml2aws login -a "$INPUT_PROFILE" \
#     --skip-prompt \
#     --password="$IDPPW" \
#     --profile="$INPUT_PROFILE" \
#     --cache-saml &&
#     export AWS_PROFILE="$INPUT_PROFILE" &&
#     export AWSCLIPARAMS="--profile=${INPUT_PROFILE}" &&
#     export AWS_DEFAULT_REGION=ap-southeast-2
#   unset IDPPW

#   # Check the login was successful
#   aws --profile "$AWS_PROFILE" sts get-caller-identity
# }

# function awslogin() {
#   if [ -z "${1}" ]; then
#     echo "ERROR: account name required, e.g. awslogin data-dev"
#   else
#     # Check credentials are current, refresh if needed and export into shell
#     aws configure list --profile "${1}" && eval "$(saml2aws script --profile "${1}")"
#   fi
# }

# Function to recursively replace the registry in package-lock.json files
npm_replace_registry() {
  # Define the string to search for and the string to replace it with
  local search_string="${LOCAL_NPM_REGISTRY}"
  local replace_string="registry.npmjs.org"

  # skip if search string is empty
  if [ -z "$search_string" ]; then
    return 0
  fi

  # Use find to locate all package-lock.json files and loop through them
  find . -type f -name 'package-lock.json' | while read -r file; do
    echo "Processing $file"

    # Use sed to perform the string replacement
    sed -i.bak "s|$search_string|$replace_string|g" "$file"

    # Remove the backup file created by sed
    rm -f "${file}.bak"

    echo "Replaced $search_string with $replace_string in $file"
  done
}

### Docker Compose ###
# Functions to help when working with docker-compose especially with multiple docker-compose files and profiles

# ddc() {
#   local command="$1"
#   shift
#   local service_name="$1"
#   shift
#   local profile=""

#   # Iterate through all docker-compose*.yaml files to find the profile
#   for file in docker-compose*.yaml; do
#     # Check if the specified service exists in the file
#     if grep -q "^  $service_name:" "$file"; then
#       # Extract profile name
#       profile_name=$(awk -v service="$service_name" '$1 == service":" { getline; getline; print $3 }' "$file")
#       profile_name="${profile_name#- }"
#       profile_name="${profile_name%\"}"
#       profile_name="${profile_name#\"}"
#       if [[ ! -z "$profile_name" ]]; then
#         profile="--profile $profile_name"
#       fi
#       break
#     fi
#   done

#   # Run the docker-compose command
#   docker-compose $profile $command "$service_name" "$@"
# }

function docker-network() {
  docker ps -q | xargs -n 1 docker inspect --format '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}} {{ .Name }}' | sed 's/ \// /' | sort
}

dpup() {
  pushd "$DOCKER_COMPOSE_DIR" || return
  docker-compose --profile "$1" up -d "$1"
  echo "----"
  docker logs -f "$1"
  popd
}

# Run docker-compose profiles on a remote (ssh) server
nas_dcup() {
  local server="$1"
  local profile="$2"
  local service="$3"
  local command="$4"

  ssh "$server" "cd ${DOCKER_COMPOSE_DIR} && docker-compose --profile ${profile} ${command} ${service}"
}

# Yazi https://github.com/sxyazi/yazi
# https://github.com/sxyazi/yazi/tree/main/config/docs
function y() {
  tmp="$(mktemp -t "yazi-cwd.XXXXX")"
  yazi --cwd-file="$tmp"
  if cwd="$(cat -- "$tmp")" && [ -n "$cwd" ] && [ "$cwd" != "$PWD" ]; then
    cd -- "$cwd"
  fi
  rm -f -- "$tmp"
}

function brewbackup() {
  # shellcheck disable=SC2139,SC2153
  brew bundle dump --force --file="/Users/${USER}/Library/Mobile Documents/com~apple~CloudDocs/Backups/homebrew/Brewfile-${HOST}"
}

# Function to reload updated Zsh functions
zsh_reload_updated_functions() {
  # Create a unique temporary file to store currently loaded functions
  local temp_file
  temp_file="/tmp/zsh_functions_$(date +%s%N)"

  # Extract currently loaded functions into the temporary file
  typeset -f >"$temp_file"

  # File containing the function definitions (e.g., ~/.zshrc)
  local source_file="$HOME/.zshrc"

  # Find updated functions
  local updated_functions
  updated_functions=$(comm -13 <(awk '/^function / {print $2}' "$temp_file" | sort) <(awk '/^function / {print $2}' "$source_file" | sort))

  # Reload updated functions
  for fn in $updated_functions; do
    unfunction "$fn" 2>/dev/null
    source "$source_file"
    echo "Reloaded function: $fn"
  done

  # Remove temporary file
  rm -f "$temp_file"
}

# Update pam to enable touchID for sudo
function touchid_sudo() {
  # Check if pam is already configured
  if grep -q "pam_tid.so" /etc/pam.d/sudo; then
    echo "pam_tid.so is already configured in /etc/pam.d/sudo"
    return 0
  fi

  cat /etc/pam.d/sudo

  # Add pam_tid.so to /etc/pam.d/sudo
  echo "Adding pam_tid.so to /etc/pam.d/sudo"
  sudo sed -i '' '1s/^/auth       sufficient     pam_tid.so\n/' /etc/pam.d/sudo
}

a() {
  # aria2c download wrapper
  # Extract filename from the URL (the part after the last slash), otherwise use provided filename
  local filename="${2:-$(basename "$1")}"

  # Base aria2c options
  local aria_opts=(
    --split=12
    --always-resume=true
    --max-tries=15
    --retry-wait=3
    --enable-http-pipelining=true
    --http-accept-gzip=true
    --max-connection-per-server=14
    --max-concurrent-downloads=5
    --min-split-size=10M
    --auto-file-renaming=false
    --content-disposition-default-utf8=true
    --disk-cache=64M
    --file-allocation=prealloc
    --out="$filename"
  )

  # Check if URL is from Huggingface
  if [[ "$1" == *"huggingface.co"* ]] || [[ "$1" == *"hf.co"* ]]; then
    # Check if HUGGINGFACE_TOKEN is set
    if [ -z "${HUGGINGFACE_TOKEN}" ]; then
      echo "Warning: HUGGINGFACE_TOKEN is not set. You may experience rate limiting."
    else
      # Verify token is valid by making a test request to the newer endpoint
      echo "Verifying Huggingface token..."
      local token_check
      token_check=$(curl -s -I -H "Authorization: Bearer ${HUGGINGFACE_TOKEN}" "https://huggingface.co/api/whoami-v2" | grep -c "HTTP/2 200")

      if [ "$token_check" -eq 1 ]; then
        echo "✅ Huggingface token is valid."
        aria_opts+=(--header="Authorization: Bearer ${HUGGINGFACE_TOKEN}")
      else
        echo "⚠️ Huggingface token appears to be invalid. Downloads may be rate limited."
        echo "Note: If your token starts with 'hf_', this is expected format for newer tokens."
        # shellcheck disable=SC2162
        read -p "Continue anyway? (y/n): " confirm
        if [[ "$confirm" != "y" ]]; then
          echo "Download cancelled."
          return 1
        fi
        # Add the token anyway as it might still work for downloads even if validation fails
        aria_opts+=(--header="Authorization: Bearer ${HUGGINGFACE_TOKEN}")
      fi
    fi
  fi

  # Run aria2c with the assembled options
  aria2c "${aria_opts[@]}" "$1"

  echo "downloaded ${1} as ${filename}"
}

rename_files() {
  # see also, one liner -  find . -name "*sdc-maps*" -exec bash -c 'mv "$0" "${0/sdc/spl}"' {} \;
  local find_word="$1"
  local replace_word="$2"
  local files_to_rename=()
  local new_names=()

  if [ -z "$find_word" ] || [ -z "$replace_word" ]; then
    echo "Usage: rename_files <find_word> <replace_word>"
    return 1
  fi

  # Collect the list of files to be renamed
  for f in *"$find_word"*; do
    if [ -e "$f" ]; then # Check if file exists
      files_to_rename+=("$f")
      new_names+=("${f//$find_word/$replace_word}")
    fi
  done

  # Display the list of files to be renamed
  echo "Files to be renamed:"
  for i in "${!files_to_rename[@]}"; do
    echo "'${files_to_rename[$i]}' -> '${new_names[$i]}'"
  done

  # Ask for confirmation
  echo "Proceed with renaming? (y/n)"
  read -r confirm
  if [ "$confirm" = "y" ] || [ "$confirm" = "Y" ]; then
    for i in "${!files_to_rename[@]}"; do
      mv "${files_to_rename[$i]}" "${new_names[$i]}"
    done
  else
    echo "Renaming cancelled."
  fi
}

hfdl() {
  local cliargs=()
  # Huggingface download wrapper
  if [[ $# -eq 0 ]]; then
    echo "Usage: hfdl <huggingface URL>"
    return 1
  fi

  local url=$1

  # if a third argument is provided, treat it as a file to download (include)
  if [[ $# -eq 2 ]]; then
    local file_to_download="$2"
    cliargs+=("--include" "$file_to_download")
  fi

  local stripped_url=$(echo "$url" | sed 's|https://huggingface.co/||')
  local owner=$(echo "$stripped_url" | cut -d'/' -f1)
  local repo=$(echo "$stripped_url" | cut -d'/' -f2)

  HF_HUB_ENABLE_HF_TRANSFER=1 huggingface-cli download "$owner/$repo" --local-dir-use-symlinks False --local-dir "$repo" "${cliargs[@]}"
}

# hide overlayfs in df
df() {
  # if macOS use /bin/df
  if [[ $(uname) == "Darwin" ]]; then
    /bin/df "$@"
    return
  fi
  /usr/bin/df -x overlay "$@"
}

gpumem() {
  # Increase the GPU memory limit for my 96GB MBP
  sudo /usr/sbin/sysctl iogpu.wired_limit_mb=86000
}

# loops through all subdirectories one level deep that are git repos and runs the specified command
function git-loop() {
  local command="$1"
  shift
  local args=("$@")

  for dir in */; do
    if [ -d "$dir/.git" ]; then
      echo "Running $command in $dir"
      git -C "$dir" "$command" "${args[@]}"
    fi
  done
}
# Register each git repo in directory with maintenance
alias git-maintenance-register="git-loop maintenance register"

# If the user runs the conda activate command before running conda init - offer to run conda init, otherwise run conda activate
function conda() {
  if [[ $1 == "activate" ]]; then
    if [[ -z $CONDA_EXE ]]; then
      echo "Conda is not initialized, would you like to initialize it? (y/n)"
      read -r response
      if [[ $response == "y" ]]; then
        conda_init
      fi
    else
      command conda "$@"
    fi
  else
    command conda "$@"
  fi
}

# a function that overrides pip commands with uv pip
function pip() {
  # if the first argument is -n, use the normal pip command
  if [[ $1 == "-n" ]]; then
    command pip "${@:2}"
    return
  fi
  echo "using uv for pip..."
  if [[ $1 == "install" ]]; then
    uv pip install "${@:2}"
  elif [[ $1 == "uninstall" ]]; then
    uv pip uninstall "${@:2}"
  else
    command pip "$@"
  fi
}

function aws-sso() {
  if [[ -z $1 ]]; then
    echo "Usage: aws-sso <profile>"
    return 1
  fi
  aws sso login --profile "$1"

  # Set the profile and region in current shell
  export AWS_PROFILE="$1"
  export AWS_REGION=ap-southeast-2

  # Get the credentials using AWS CLI and set them in the current shell
  eval "$(aws configure export-credentials --format env --profile "$1")"

  # Create a temporary file only user can access for short-lived, rotating credentials
  mkdir -p "${HOME}/.tmp"
  local aws_creds_file
  aws_creds_file="${HOME}/.tmp/awltmp"
  rm -f "$aws_creds_file"

  # Write the current environment variables to the file
  cat > "$aws_creds_file" << EOF
export AWS_SESSION_TOKEN='$AWS_SESSION_TOKEN'
export AWS_ACCESS_KEY_ID='$AWS_ACCESS_KEY_ID'
export AWS_SECRET_ACCESS_KEY='$AWS_SECRET_ACCESS_KEY'
export AWS_PROFILE='$1'
export AWS_REGION='ap-southeast-2'
EOF

  chmod 600 "$aws_creds_file"

  echo "AWS credentials exported to $aws_creds_file"
  echo "Run the following in other terminals to source the credentials:"
  echo "source $aws_creds_file"
}
alias aws-ai="aws-sso aisandpit"
# shellcheck disable=SC2139
alias awl="source ${HOME}/.tmp/awltmp"

function aws-nas() {
  /Users/samm/Library/Mobile\ Documents/com~apple~CloudDocs/Dropbox\ Import/dotfiles/shell_config/update-aws-creds.sh aisandpit
}

if_not_in_vscode() {
  # if not running in vscode, run the rest of the arguments
  # requires setting RUNNING_IN_VSCODE to true in vscode's terminal env settings:
  #   {
  #   "terminal.integrated.env.osx": {
  #     "RUNNING_IN_VSCODE": "true"
  #   }

  if [ -z "$RUNNING_IN_VSCODE" ]; then
    "$@"
  fi
}

# q() {
  # DISABLED as Q is being replaced with Kiro-CLI
  # Amazon Q wrapper because their Q CLI installer completely hoses terminal performance
  # https://github.com/aws/amazon-q-developer-cli/issues/844
  # https://github.com/aws/amazon-q-developer-cli/discussions/202
  # doesn't quite work yet as their MCP integrations seem to fail, e.g
  # failed installing shell integration bash pre post into .bashrc err=Integration not installed: /Users/samm/.bashrc does not source pre integration
  # Failed installing shell integration bash pre post into .profile err=File does not exist: /Users/samm/.profile
  # Failed installing shell integration zsh pre post into .zshrc err=Integration not installed: /Users/samm/.zshrc does not source pre integration
  # Failed installing shell integration zsh pre post into .zprofile err=Integration not installed: /Users/samm/.zprofile does not source pre integration
#   # Amazon Q pre block for .zprofile
#   [[ -f "${HOME}/Library/Application Support/amazon-q/shell/zprofile.pre.zsh" ]] && builtin source "${HOME}/Library/Application Support/amazon-q/shell/zprofile.pre.zsh"
#   # Amazon Q post block for .zprofile
#   [[ -f "${HOME}/Library/Application Support/amazon-q/shell/zprofile.post.zsh" ]] && builtin source "${HOME}/Library/Application Support/amazon-q/shell/zprofile.post.zsh"

#   # Amazon Q pre block for .zshrc
#   [[ -f "${HOME}/Library/Application Support/amazon-q/shell/zshrc.pre.zsh" ]] && builtin source "${HOME}/Library/Application Support/amazon-q/shell/zshrc.pre.zsh"
#   # Amazon Q post block for .zshrc
#   [[ -f "${HOME}/Library/Application Support/amazon-q/shell/zshrc.post.zsh" ]] && builtin source "${HOME}/Library/Application Support/amazon-q/shell/zshrc.post.zsh"

#   command /Users/samm/.local/bin/q "$@"
# }

cline-workflows() {
  SOURCE_DIR="/Users/samm/git/sammcj/agentic-coding/Cline/Rules/workflows"
  DEST_DIR=.clinerules/workflows

  read -r -p "This will copy all workflows from $SOURCE_DIR to $DEST_DIR. Do you want to proceed? (y/n): " choice
  if [[ $choice != [yY] ]]; then
    echo "Aborting..."
    return 1
  fi
  mkdir -p $DEST_DIR
  cp -r $SOURCE_DIR/*.md $DEST_DIR/
}

# Override cd to handle 'cd -' with zoxide compatibility
cd() {
  # If called with '-' argument, use zoxide's z - instead
  if [[ "$1" == "-" ]]; then
    z -
  else
    # For all other cases, use zoxide's cd (which is already overridden by zoxide init)
    builtin cd "$@"
  fi
}


# Quick navigation to git repositories, optionally taking a subdirectory as an argument
_git_nav() {
    local cmd="$1"
    shift  # Remove the command from arguments
    local base_dir

    case "$cmd" in
        "gs")
            base_dir="$HOME/git/sammcj"
            ;;
        "gm")
            base_dir="$HOME/git/mantel"
            ;;
        "g")
            base_dir="$HOME/git"
            ;;
        *)
            echo "Unknown git navigation command: $cmd"
            return 1
            ;;
    esac

    if [[ $# -eq 0 ]]; then
        cd "$base_dir"
    else
        local target_dir="$base_dir/$1"
        if [[ -d "$target_dir" ]]; then
            cd "$target_dir"
        else
            cd "$base_dir"
            echo "Directory '$1' not found in $base_dir"
        fi
    fi
}
# Use the git quick navigation function
gs() { _git_nav "gs" "$@"; }
gm() { _git_nav "gm" "$@"; }
g() { _git_nav "g" "$@"; }


# NPM Package Updater Function to update all global packages with error recovery
# Automatically handles ENOTEMPTY errors by removing problematic directories
# and reinstalling packages individually when batch install fails
npm-global-update() {
    # TODO: switch to pnpm, detect if packages are installed with pnpm or npm and use the appropriate tool or migrated npm packages to pnpm
    # Define allowed package patterns (substring matches)
    local allowed_patterns
    allowed_patterns=("@anthropic-ai/claude-code" "@google/gemini-cli" "@qwen-code/qwen-code" "ccstatusline" "claude-code-router" "claudekit" "ccusage" "npm-check-updates" "playwright" "ccexp" "vibe-kanban" "@vscode/vsce" "yaml-language-server" "typescript-language-server" "typescript" "corepack" "npm" "pnpm" "jest" "tweakcc" "@modelcontextprotocol/inspector" "happy-coder" "@github/copilot" "cline@nightly" "cline" "@anthropic-ai/sandbox-runtime" "@kimuson/claude-code-viewer@latest")

    echo "🔍 Checking for global package updates..."

    # Run npm-check-updates and capture output
    local ncu_output
    ncu_output=$(npm-check-updates -g 2>/dev/null)

    if [[ $? -ne 0 ]]; then
        echo "❌ Failed to run npm-check-updates. Make sure it's installed globally."
        return 1
    fi

    # Extract package updates (lines with →)
    local updates
    updates=$(echo "$ncu_output" | grep "→" | sed 's/^ *//')

    if [[ -z "$updates" ]]; then
        echo "✅ All global packages are up to date!"
        return 0
    fi

    echo "Package upgrade allowlist: ${allowed_patterns[*]}"
    echo "-----------------------------------"
    echo "📦 Found updates:"
    echo "$updates"
    echo

    # Parse package names and versions, filtering by allowed patterns
    local packages=()
    while IFS= read -r line; do
        if [[ -n "$line" ]]; then
            # Extract package@version from "package 1.0.0 → 1.0.1" format
            local pkg_name new_version
            pkg_name=$(echo "$line" | awk '{print $1}')
            new_version=$(echo "$line" | awk '{print $4}')

            # Check if package matches any allowed pattern
            local matches_pattern=false
            for pattern in "${allowed_patterns[@]}"; do
                if [[ "$pkg_name" == "$pattern" ]]; then # it was  *"$pattern"*, but that's unsafe
                    matches_pattern=true
                    break
                fi
            done

            if [[ "$matches_pattern" == true ]]; then
                packages+=("${pkg_name}@${new_version}")
            fi
        fi
    done <<< "$updates"

    if [[ ${#packages[@]} -eq 0 ]]; then
        echo "❌ No packages found to update"
        return 1
    fi

    echo "🚀 Attempting to install ${#packages[@]} update(s)..."

    # Try to install all packages at once
    local install_output install_exit_code
    install_output=$(npm -g install "${packages[@]}" 2>&1)
    install_exit_code=$?

    if [[ $install_exit_code -eq 0 ]]; then
        echo "✅ All packages updated successfully!"
        return 0
    fi

    # If batch install failed, check if it's due to ENOTEMPTY errors
    if echo "$install_output" | grep -q "ENOTEMPTY"; then
        echo "⚠️  Batch install failed due to ENOTEMPTY errors. Trying individual recovery..."
        echo

        # Extract failed package paths from error output
        local failed_packages=()
        while IFS= read -r error_line; do
            if [[ "$error_line" == "npm error path "* ]]; then
                # Extract path using string manipulation instead of regex
                local error_path="${error_line#npm error path }"
                # Extract package name from path
                local pkg_from_path
                pkg_from_path=$(basename "$error_path")
                failed_packages+=("$error_path:$pkg_from_path")
            fi
        done <<< "$install_output"

        # Process each failed package
        local recovery_needed=()
        for package_info in "${failed_packages[@]}"; do
            local path_part name_part
            path_part="${package_info%%:*}"
            name_part="${package_info##*:}"

            # Find corresponding package@version from our list
            local target_package=""
            for pkg in "${packages[@]}"; do
                local pkg_name
                pkg_name="${pkg%%@*}"
                if [[ "$name_part" == "$pkg_name" ]] || [[ "$path_part" =~ $pkg_name$ ]]; then
                    target_package="$pkg"
                    break
                fi
            done

            if [[ -n "$target_package" ]]; then
                recovery_needed+=("$path_part:$target_package")
            fi
        done

        # Remove and reinstall each problematic package
        for recovery_info in "${recovery_needed[@]}"; do
            local path_to_remove package_to_install
            path_to_remove="${recovery_info%%:*}"
            package_to_install="${recovery_info##*:}"

            echo "🔧 Fixing ${package_to_install}..."
            echo "   Removing: $path_to_remove"

            if [[ -d "$path_to_remove" ]]; then
                rm -rf "$path_to_remove"
                npm -g uninstall "${package_to_install%%@*}" 2>/dev/null
                if [[ $? -eq 0 ]]; then
                    echo "   ✅ Removed successfully"
                else
                    echo "   ❌ Failed to remove $path_to_remove"
                    continue
                fi
            else
                echo "   ⚠️  Path doesn't exist: $path_to_remove"
            fi

            echo "   Installing: $package_to_install"
            if npm -g install "$package_to_install"; then
                echo "   ✅ Installed successfully"
            else
                echo "   ❌ Failed to install $package_to_install"
            fi
            echo
        done

        # Try to install any remaining packages that weren't in the error list
        local remaining_packages=()
        for pkg in "${packages[@]}"; do
            local pkg_name
            pkg_name="${pkg%%@*}"
            local found_in_errors=false

            for recovery_info in "${recovery_needed[@]}"; do
                local recovery_pkg
                recovery_pkg="${recovery_info##*:}"
                if [[ "$pkg" == "$recovery_pkg" ]]; then
                    found_in_errors=true
                    break
                fi
            done

            if [[ "$found_in_errors" == false ]]; then
                remaining_packages+=("$pkg")
            fi
        done

        if [[ ${#remaining_packages[@]} -gt 0 ]]; then
            echo "🔄 Installing remaining packages..."
            for pkg in "${remaining_packages[@]}"; do
                echo "   Installing: $pkg"
                if npm -g install "$pkg"; then
                    echo "   ✅ Installed successfully"
                else
                    echo "   ❌ Failed to install $pkg"
                fi
            done
        fi

        echo "🏁 Recovery process completed!"
    else
        echo "❌ Batch install failed with different error:"
        echo "$install_output"
        return 1
    fi
}
alias ngu="npm-global-update"

# g2rg - Grep to Ripgrep Converter
# A complete solution for converting grep commands to ripgrep syntax
#
# Features:
# - Manual conversion: g2rg "grep -ri 'pattern' ." or g2rg "-ri 'pattern' ."
# - Command conversion: rgrep [grep-args] - converts and executes grep commands using ripgrep
# - Original grep is preserved and accessible via the standard grep command
#
# Usage: source this file in your .zshrc

# ============================================================================
# Manual conversion function
# ============================================================================

g2rg() {
    if [[ $# -eq 0 ]]; then
        echo "Usage: g2rg <grep-command>"
        echo "Example: g2rg \"grep -ri 'nodejs' . --exclude-dir .git\""
        echo "Example: g2rg \"-ri 'nodejs' . --exclude-dir .git\""
        return 1
    fi

    local input="$*"
    local output="rg"
    local pattern=""
    local search_path="."
    local glob_excludes=()

    # Check if input starts with 'grep' and remove it
    if [[ $input == grep\ * ]]; then
        input=${input#grep }
    fi

    # Parse arguments whilst preserving quoted strings
    local -a args
    eval "args=($input)"

    local i=1
    local pattern_found=false

    while [[ $i -le ${#args[@]} ]]; do
        local word=${args[$i]}

        # Handle combined flags like -ri, -rn, etc.
        if [[ $word =~ ^-[a-zA-Z]{2,}$ ]] && [[ $word != --* ]]; then
            # Split combined flags (e.g., -ri becomes -r -i)
            local flags=${word#-}
            for (( j=1; j<=${#flags}; j++ )); do
                local pos=$((j-1))
                local flag=${flags:$pos:1}
                case $flag in
                    r|R)
                        # ripgrep is recursive by default
                        ;;
                    i)
                        output="$output -i"
                        ;;
                    v)
                        output="$output -v"
                        ;;
                    n)
                        output="$output -n"
                        ;;
                    H)
                        output="$output -H"
                        ;;
                    h)
                        output="$output -h"
                        ;;
                    l)
                        output="$output -l"
                        ;;
                    L)
                        output="$output -L"
                        ;;
                    c)
                        output="$output -c"
                        ;;
                    w)
                        output="$output -w"
                        ;;
                    x)
                        output="$output -x"
                        ;;
                    *)
                        # Unknown single flag, pass it through
                        output="$output -$flag"
                        ;;
                esac
            done
        else
            case $word in
                -r|-R|--recursive)
                    # ripgrep is recursive by default
                    ;;
                -i|--ignore-case)
                    output="$output -i"
                    ;;
                -v|--invert-match)
                    output="$output -v"
                    ;;
                -n|--line-number)
                    output="$output -n"
                    ;;
                -H|--with-filename)
                    output="$output -H"
                    ;;
                -h|--no-filename)
                    output="$output -h"
                    ;;
                -l|--files-with-matches)
                    output="$output -l"
                    ;;
                -L|--files-without-match)
                    output="$output --files-without-match"
                    ;;
                -c|--count)
                    output="$output -c"
                    ;;
                -w|--word-regexp)
                    output="$output -w"
                    ;;
                -x|--line-regexp)
                    output="$output -x"
                    ;;
                -A*)
                    if [[ $word == "-A" ]]; then
                        ((i++))
                        local num=${args[$i]}
                        output="$output -A $num"
                    else
                        local num=${word#-A}
                        output="$output -A $num"
                    fi
                    ;;
                -B*)
                    if [[ $word == "-B" ]]; then
                        ((i++))
                        local num=${args[$i]}
                        output="$output -B $num"
                    else
                        local num=${word#-B}
                        output="$output -B $num"
                    fi
                    ;;
                -C*)
                    if [[ $word == "-C" ]]; then
                        ((i++))
                        local num=${args[$i]}
                        output="$output -C $num"
                    else
                        local num=${word#-C}
                        output="$output -C $num"
                    fi
                    ;;
                --exclude-dir)
                    ((i++))
                    local dir_pattern=${args[$i]}
                    if [[ $dir_pattern == */* ]]; then
                        glob_excludes+=("!$dir_pattern")
                    else
                        glob_excludes+=("!$dir_pattern/*")
                    fi
                    ;;
                --exclude)
                    ((i++))
                    local file_pattern=${args[$i]}
                    glob_excludes+=("!$file_pattern")
                    ;;
                -*)
                    output="$output $word"
                    ;;
                *)
                    if [[ $pattern_found == false ]]; then
                        pattern=$word
                        pattern_found=true
                    else
                        search_path=$word
                    fi
                    ;;
            esac
        fi
        ((i++))
    done

    # Build the final ripgrep command
    if [[ -n $pattern ]]; then
        # Escape the pattern properly for ripgrep
        pattern=${pattern//\\/\\\\}  # Escape backslashes
        output="$output $(printf %q "$pattern")"
    fi

    output="$output $search_path"

    for exclude in "${glob_excludes[@]}"; do
        output="$output --glob $(printf %q "$exclude")"
    done

    echo "$output"
}

# Convert and execute
g2rg-exec() {
    local rg_command
    rg_command=$(g2rg "$@")
    echo "Executing: $rg_command"
    eval "$rg_command"
}

# ============================================================================
# rgrep function (interactive shells only)
# ============================================================================

if [[ -o interactive ]] || [[ -n $ZSH_VERSION ]]; then

  # Direct argument version of g2rg for stdin input
  g2rg-direct-stdin() {
      local output="rg"
      local pattern=""
      local glob_excludes=()
      local pattern_found=false

      local args=("$@")
      local i=1
      while [[ $i -le $# ]]; do
          local word="${args[$i]}"

          # Handle combined flags like -ri, -rn, etc.
          if [[ $word =~ ^-[a-zA-Z]{2,}$ ]] && [[ $word != --* ]]; then
              # Split combined flags (e.g., -ri becomes -r -i)
              local flags=${word#-}
              for (( j=1; j<=${#flags}; j++ )); do
                  local pos=$((j-1))
                  local flag=${flags:$pos:1}
                  case $flag in
                      r|R)
                          # ripgrep reads stdin when no files specified
                          ;;
                      i) output="$output -i" ;;
                      v) output="$output -v" ;;
                      n) output="$output -n" ;;
                      H) output="$output -H" ;;
                      h) output="$output -h" ;;
                      l) output="$output -l" ;;
                      L) output="$output -L" ;;
                      c) output="$output -c" ;;
                      w) output="$output -w" ;;
                      x) output="$output -x" ;;
                      *) output="$output -$flag" ;;
                  esac
              done
          else
              case $word in
                  -r|-R|--recursive)
                      # not relevant for stdin
                      ;;
                  -i|--ignore-case) output="$output -i" ;;
                  -v|--invert-match) output="$output -v" ;;
                  -n|--line-number) output="$output -n" ;;
                  -H|--with-filename) output="$output -H" ;;
                  -h|--no-filename) output="$output -h" ;;
                  -l|--files-with-matches) output="$output -l" ;;
                  -L|--files-without-match) output="$output --files-without-match" ;;
                  -c|--count) output="$output -c" ;;
                  -w|--word-regexp) output="$output -w" ;;
                  -x|--line-regexp) output="$output -x" ;;
                  -A*)
                      if [[ $word == "-A" ]]; then
                          ((i++))
                          local num="${!i}"
                          output="$output -A $num"
                      else
                          local num=${word#-A}
                          output="$output -A $num"
                      fi
                      ;;
                  -B*)
                      if [[ $word == "-B" ]]; then
                          ((i++))
                          local num="${!i}"
                          output="$output -B $num"
                      else
                          local num=${word#-B}
                          output="$output -B $num"
                      fi
                      ;;
                  -C*)
                      if [[ $word == "-C" ]]; then
                          ((i++))
                          local num="${!i}"
                          output="$output -C $num"
                      else
                          local num=${word#-C}
                          output="$output -C $num"
                      fi
                      ;;
                  --exclude-dir|--exclude)
                      ((i++))
                      # Skip exclude patterns for stdin - not relevant
                      ;;
                  -*)
                      output="$output $word"
                      ;;
                  *)
                      if [[ $pattern_found == false ]]; then
                          pattern=$word
                          pattern_found=true
                      fi
                      # Skip additional arguments (would be file paths) for stdin
                      ;;
              esac
          fi
          ((i++))
      done

      # Build the final ripgrep command for stdin
      if [[ -n $pattern ]]; then
          output="$output $(printf %q "$pattern")"
      fi

      # Don't add any file paths - ripgrep will read from stdin

      echo "$output"
  }

  # Direct argument version of g2rg for the grep function
  g2rg-direct() {
      local output="rg"
      local pattern=""
      local search_path="."
      local glob_excludes=()
      local pattern_found=false

      local args=("$@")
      local i=1
      while [[ $i -le $# ]]; do
          local word="${args[$i]}"

          # Handle combined flags like -ri, -rn, etc.
          if [[ $word =~ ^-[a-zA-Z]{2,}$ ]] && [[ $word != --* ]]; then
              # Split combined flags (e.g., -ri becomes -r -i)
              local flags=${word#-}
              for (( j=1; j<=${#flags}; j++ )); do
                  local pos=$((j-1))
                  local flag=${flags:$pos:1}
                  case $flag in
                      r|R)
                          # ripgrep is recursive by default
                          ;;
                      i) output="$output -i" ;;
                      v) output="$output -v" ;;
                      n) output="$output -n" ;;
                      H) output="$output -H" ;;
                      h) output="$output -h" ;;
                      l) output="$output -l" ;;
                      L) output="$output -L" ;;
                      c) output="$output -c" ;;
                      w) output="$output -w" ;;
                      x) output="$output -x" ;;
                      *) output="$output -$flag" ;;
                  esac
              done
          else
              case $word in
                  -r|-R|--recursive)
                      # ripgrep is recursive by default
                      ;;
                  -i|--ignore-case) output="$output -i" ;;
                  -v|--invert-match) output="$output -v" ;;
                  -n|--line-number) output="$output -n" ;;
                  -H|--with-filename) output="$output -H" ;;
                  -h|--no-filename) output="$output -h" ;;
                  -l|--files-with-matches) output="$output -l" ;;
                  -L|--files-without-match) output="$output --files-without-match" ;;
                  -c|--count) output="$output -c" ;;
                  -w|--word-regexp) output="$output -w" ;;
                  -x|--line-regexp) output="$output -x" ;;
                  -A*)
                      if [[ $word == "-A" ]]; then
                          ((i++))
                          local num="${!i}"
                          output="$output -A $num"
                      else
                          local num=${word#-A}
                          output="$output -A $num"
                      fi
                      ;;
                  -B*)
                      if [[ $word == "-B" ]]; then
                          ((i++))
                          local num="${!i}"
                          output="$output -B $num"
                      else
                          local num=${word#-B}
                          output="$output -B $num"
                      fi
                      ;;
                  -C*)
                      if [[ $word == "-C" ]]; then
                          ((i++))
                          local num="${!i}"
                          output="$output -C $num"
                      else
                          local num=${word#-C}
                          output="$output -C $num"
                      fi
                      ;;
                  --exclude-dir)
                      ((i++))
                      local dir_pattern="${!i}"
                      if [[ $dir_pattern == */* ]]; then
                          glob_excludes+=("!$dir_pattern")
                      else
                          glob_excludes+=("!$dir_pattern/*")
                      fi
                      ;;
                  --exclude)
                      ((i++))
                      local file_pattern="${!i}"
                      glob_excludes+=("!$file_pattern")
                      ;;
                  -*)
                      output="$output $word"
                      ;;
                  *)
                      if [[ $pattern_found == false ]]; then
                          pattern=$word
                          pattern_found=true
                      else
                          search_path=$word
                      fi
                      ;;
              esac
          fi
          ((i++))
      done

      # Build the final ripgrep command
      if [[ -n $pattern ]]; then
          output="$output $(printf %q "$pattern")"
      fi

      output="$output $search_path"

      for exclude in "${glob_excludes[@]}"; do
          output="$output --glob $(printf %q "$exclude")"
      done

      echo "$output"
  }

  # Enhanced ripgrep function (use rgrep to convert grep commands to ripgrep)
  rgrep() {
      # Check if ripgrep is available
      if ! command -v rg &> /dev/null; then
          echo "Warning: ripgrep (rg) not found, falling back to original grep" >&2
          command grep "$@"
          return $?
      fi

      # Check if stdin is being piped
      local use_stdin=false
      if [[ ! -t 0 ]]; then
          use_stdin=true
      fi

      # Pass arguments directly instead of building a string
      local rg_cmd
      if [[ $use_stdin == true ]]; then
          rg_cmd=$(g2rg-direct-stdin "$@")
      else
          rg_cmd=$(g2rg-direct "$@")
      fi

      # Show conversion if verbose mode is enabled
      if [[ -n $GREP_TO_RG_VERBOSE ]]; then
          echo "# Converting grep with ${#@} arguments" >&2
          echo "# Using stdin: $use_stdin" >&2
          echo "# Running: $rg_cmd" >&2
      fi

      # Execute the ripgrep command
      eval "$rg_cmd"
  }

  # ========================================================================
  # Helper functions
  # ========================================================================

  # Toggle verbose mode for rgrep
  rgrep-verbose-on() {
      export GREP_TO_RG_VERBOSE=1
      echo "rgrep verbose mode enabled"
  }

  rgrep-verbose-off() {
      unset GREP_TO_RG_VERBOSE
      echo "rgrep verbose mode disabled"
  }

  # Show status
  rgrep-status() {
      echo "rgrep Status:"
      echo "  Verbose mode: $(if [[ -n $GREP_TO_RG_VERBOSE ]]; then echo "enabled"; else echo "disabled"; fi)"
      echo "  Ripgrep available: $(if command -v rg &> /dev/null; then echo "yes"; else echo "no"; fi)"
      echo ""
      echo "Commands:"
      echo "  g2rg \"command\"        - Convert grep command to ripgrep"
      echo "  g2rg-exec \"command\"   - Convert and execute"
      echo "  rgrep [grep-args]     - Convert grep arguments to ripgrep and execute"
      echo "  rgrep-verbose-on/off  - Toggle conversion display"
      echo "  rgrep-status          - Show this status"
  }
fi

yt-dlp() {
  # Downloads the provided video with subtitles using the browsers cookies to ~/Downloads/videos
  # and converts the subs to a plain txt file
  local base_name output_file video_dir converted_count

  video_dir="${HOME}/Downloads/videos"
  mkdir -p "$video_dir"

  if ! command yt-dlp --write-subs --write-auto-subs --sub-format json3 --sub-lang en \
    --cookies-from-browser firefox --remote-components ejs:github \
    -f "bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best" \
    -o "$video_dir/%(title)s.%(ext)s" "$@"; then
    echo "yt-dlp failed to download video"
    return 1
  fi

  # Convert any json3 files in the video directory
  converted_count=0
  for file in "$video_dir"/*.json3; do
    [[ -e "$file" ]] || continue
    base_name="${file%.json3}"
    output_file="${base_name}.txt"
    echo "Converting $file to $output_file"
    if jq -r '[.events[].segs[]?.utf8] | join("") | gsub("[\n ]+"; " ")' "$file" > "$output_file"; then
      rm "$file"
      echo "Cleaned up $file"
      ((converted_count++))
    else
      echo "Failed to convert $file"
    fi
  done

  if [[ $converted_count -eq 0 ]]; then
    echo "No subtitles found or downloaded for this video"
  fi
}

# Intelligently generate shell completions with file completion support
# Usage: generate_zsh_completions <tool> <subcommand> [file_pattern]
# Examples:
#   generate_zsh_completions uv run "*.py"
#   generate_zsh_completions mycommand process "*"
#   generate_zsh_completions rg search "*.txt"
generate_zsh_completions() {
    # Show help if no arguments or help flag
    if [[ $# -eq 0 ]] || [[ "${1}" == "-h" ]] || [[ "${1}" == "--help" ]]; then
        cat <<'HELP'
Setup shell completion with file pattern matching

Usage: generate_zsh_completions <tool> <subcommand> [file_pattern]

Arguments:
  tool          - Command name (e.g. uv, rg, mycommand)
  subcommand    - Subcommand that takes files (e.g. run, process)
  file_pattern  - Optional glob pattern for files (default: "*")
                  Examples: "*.py", "*.{json,yaml}", "*.txt"

Examples:
  generate_zsh_completions uv run "*.py"
  generate_zsh_completions poetry run "*.py"
  generate_zsh_completions mycommand process "*"
  generate_zsh_completions rg search "*.{md,txt}"

The function will automatically detect if the tool has built-in
completion support and use the appropriate method.
HELP
        return 0
    fi

    local tool="${1}"
    local subcommand="${2}"
    local file_pattern="${3:-*}"
    local custom_dir="${HOME}/.oh-my-zsh/custom"
    local completion_file="${custom_dir}/${tool}-completion.zsh"

    if ! command -v "${tool}" &> /dev/null; then
        echo "Error: ${tool} not found in PATH"
        return 1
    fi

    mkdir -p "${custom_dir}"

    # Try to detect if the tool supports built-in shell completion
    local has_builtin_completion=false

    if "${tool}" generate-shell-completion zsh &>/dev/null 2>&1; then
        has_builtin_completion=true
    elif "${tool}" completion zsh &>/dev/null 2>&1; then
        has_builtin_completion=true
    elif "${tool}" --help 2>&1 | grep -qE "(completion|generate.*shell)"; then
        echo "Note: ${tool} may support completions, but couldn't auto-detect the command"
        echo "Check '${tool} --help' and update the function if needed"
    fi

    if [[ "${has_builtin_completion}" == "true" ]]; then
        echo "Detected built-in completion support for ${tool}"
        cat > "${completion_file}" <<EOF
# Enhanced completion for ${tool} with built-in generation
# Generated on $(date)

if command -v ${tool} &> /dev/null; then
    eval "\$(${tool} generate-shell-completion zsh)"
fi

_${tool}_enhanced() {
    if [[ \${words[2]} == "${subcommand}" ]]; then
        _files -g "${file_pattern}"
        return 0
    fi
    _${tool} "\$@"
}

compdef _${tool}_enhanced ${tool}
EOF
    else
        echo "No built-in completion detected, creating simple file completion for ${tool}"
        cat > "${completion_file}" <<EOF
# Simple file completion for ${tool}
# Generated on $(date)

_${tool}_simple() {
    if [[ \${words[2]} == "${subcommand}" ]]; then
        _files -g "${file_pattern}"
        return 0
    fi
    _arguments "1:subcommand:(${subcommand})"
}

compdef _${tool}_simple ${tool}
EOF
    fi

    echo "Created ${completion_file}"
    echo "Run 'exec zsh' or restart your terminal to apply changes"
}

# ============================================================================
# Git Worktree Helpers
# ============================================================================

# Fast repo root finder (no git subprocess)
_wt_find_repo_root() {
  local dir="$PWD"
  while [[ "$dir" != "/" ]]; do
    if [[ -f "$dir/.git" ]]; then
      # Worktree - .git file contains: gitdir: /path/.git/worktrees/NAME
      local gitdir_line
      gitdir_line=$(<"$dir/.git")
      gitdir_line="${gitdir_line#gitdir: }"
      # Main repo is parent of .git/worktrees/NAME
      echo "${gitdir_line%/.git/worktrees/*}"
      return
    elif [[ -d "$dir/.git" ]]; then
      echo "$dir"
      return
    fi
    dir="${dir:h}"
  done
  return 1
}

# List all worktrees
wt() {
  git worktree list
}

# Add a new worktree as a sibling directory
wta() {
  local name="${1:?Usage: wta <name> [base-branch]}"
  local base="${2:-HEAD}"
  local repo_root
  repo_root=$(_wt_find_repo_root) || { echo "Not in a git repository"; return 1; }
  local target="${repo_root:h}/${name}"

  git worktree add -b "$name" "$target" "$base" && \
    echo "Created worktree: $target"
}

# Remove a worktree (with fzf selection if no name given)
wtr() {
  local name="$1"
  local wt_path
  if [[ -z "$name" ]]; then
    wt_path=$(git worktree list | tail -n +2 | fzf --height=40% --prompt="Remove worktree: " | awk '{print $1}')
    [[ -z "$wt_path" ]] && return 1
  else
    wt_path=$(git worktree list | awk -v name="/$name " '$0 ~ name {print $1}')
  fi
  [[ -z "$wt_path" ]] && { echo "Worktree not found"; return 1; }
  git worktree remove "$wt_path" && git worktree prune
}

# Change directory to a worktree (with fzf selection if no name given)
wtcd() {
  local target
  if [[ -n "$1" ]]; then
    target=$(git worktree list | awk -v name="/$1 " '$0 ~ name {print $1}')
  else
    target=$(git worktree list | fzf --height=40% --prompt="Switch to: " | awk '{print $1}')
  fi
  if [[ -n "$target" && -d "$target" ]]; then
    cd "$target"
  else
    echo "Worktree not found"
    return 1
  fi
}

# Jump to the main worktree (fast, no git subprocess)
wtmain() {
  local main
  main=$(_wt_find_repo_root) || { echo "Not in a git repository"; return 1; }
  cd "$main"
}

# Clone a repo in bare-repo + worktrees layout for worktree-first workflow
wtclone() {
  local url="${1:?Usage: wtclone <repo-url>}"
  local name="${url:t:r}"  # zsh: tail then remove extension
  local bare_dir="${name}.git"

  git clone --bare "$url" "$bare_dir" || return 1
  cd "$bare_dir" || return 1

  # Determine default branch
  local default_branch
  default_branch=$(git symbolic-ref --short HEAD 2>/dev/null || echo "main")

  # Create first worktree
  git worktree add "../${name}" "$default_branch" || return 1
  cd "../${name}" || return 1
  echo "Bare repo: ../${bare_dir}"
  echo "Worktree:  $(pwd)"
}
